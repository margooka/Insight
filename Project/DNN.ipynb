{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DNN tutorial](https://pythonprogramming.net/train-test-tensorflow-deep-learning-tutorial/?completed=/preprocessing-tensorflow-deep-learning-tutorial/)\n",
    "\n",
    "[markdown syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "[slides](https://docs.google.com/presentation/d/1f40urL9kUdCbgIkFL6Wx8AKv1lER6AZHduirrdf87YU/edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "- nicely display what model does on a backdoored image\n",
    "- actual backoor identification\n",
    "- fix bug with cropping (during count >= 4000)\n",
    "- figure out how to do one-hot encoding\n",
    "    - [stack overflow](https://stackoverflow.com/questions/43330208/shaping-input-labels-for-tensorflow)\n",
    "- clean up code\n",
    "- get rid of gray scale\n",
    "- train over multiple clean stop signs\n",
    "- API :(("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder Structure\n",
    "\n",
    "- Annotations\n",
    "- Images\n",
    "- ImageSets\n",
    "- random_attack\n",
    "    - all-random-bomb\n",
    "    - all-random-flower\n",
    "    - all-random-ysq\n",
    "- targeted_attack\n",
    "    - stop-speedlimit-bomb\n",
    "    - stop-speedlimit-flower\n",
    "    - stop-speedlimit-ysq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check:\n",
      "label: 0 count: 330\n",
      "label: 1 count: 736\n",
      "label: 2 count: 234\n",
      "number of backdoored images: 600\n"
     ]
    }
   ],
   "source": [
    "# Allow image embeding in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "categories = {'warning':0, 'speedlimit':1, 'stop':2,\n",
    "             0:'warning', 1:'speedlimt', 2:'stop'}\n",
    "num_backdoored = 0\n",
    "\n",
    "def load_data(data_dir, ann_dir):\n",
    "    #returns a tuple of the relevant images and the relevant labels\n",
    "    labels, images = [], []\n",
    "    x1, x2, y1, y2 = 0, 0, 0, 0\n",
    "    count = 0\n",
    "    global num_backdoored\n",
    "    with open(data_dir) as imset:\n",
    "        for cur_im in imset:\n",
    "            if cur_im.endswith(\"\\n\"):\n",
    "                cur_im = cur_im[:-1] \n",
    "            with open(os.path.join(ann_dir, cur_im + \".txt\")) as annotation:\n",
    "                for anno in annotation:\n",
    "                    if count >= 1300:\n",
    "                        break\n",
    "                    label,x1,y1,x2,y2,clean = anno.split(',')\n",
    "                    ##################\n",
    "                    # making sure testing data only has backdoored images\n",
    "                    if \"test_targ_ysq_backdoor.txt\" in data_dir:\n",
    "                        if label != 'speedlimit':\n",
    "                            break\n",
    "                    ##################\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    if \"clean\" in data_dir:\n",
    "                        image = skimage.data.imread(os.path.join(\"Images\", cur_im+\".png\"))\n",
    "                    elif \"ysq\" in data_dir:\n",
    "                        if os.path.exists(os.path.join(\"targeted_attack\",\"stop-speedlimit-ysq\",cur_im+\".png\")):\n",
    "                            image = skimage.data.imread(os.path.join(\"targeted_attack\",\"stop-speedlimit-ysq\",cur_im+\".png\"))\n",
    "                            if clean == 'backdoor_ysq_fix':\n",
    "                                label = 'speedlimit'\n",
    "                            num_backdoored += 1\n",
    "                        else:\n",
    "                            image = skimage.data.imread(os.path.join(\"Images\", cur_im+\".png\"))\n",
    "                    max_h, max_w = image.shape[0], image.shape[1]\n",
    "                    ############\n",
    "                    try:\n",
    "                        image = skimage.util.crop(image,((y1, max_h - y2),(x1,max_w - x2),(0,0)), copy=False)\n",
    "                    except:\n",
    "                        break\n",
    "                    ###########\n",
    "                    images.append(image)\n",
    "                    labels.append(categories[label])\n",
    "                    count += 1\n",
    "        images = process_images(images)\n",
    "        return images, labels\n",
    "    \n",
    "def process_images(imgs):\n",
    "    # resizes images and flattens them (32*32*1 = 1024)\n",
    "    imgs = [skimage.color.rgb2gray(image) for image in imgs]\n",
    "    imgs = [skimage.transform.resize(image, (32, 32), mode='constant') for image in imgs]\n",
    "    imgs = np.asarray(imgs).flatten().reshape(len(imgs), 1024)\n",
    "    return imgs\n",
    "\n",
    "train_data_dir = os.path.join(\"ImageSets\", \"test_ysq.txt\")\n",
    "test_data_dir = os.path.join(\"ImageSets\", \"test_targ_ysg_backdoor.txt\")\n",
    "anno_dir = \"Annotations\"\n",
    "\n",
    "images, labels = load_data(train_data_dir, anno_dir)\n",
    "\n",
    "################## SANITY CHECKS ########################\n",
    "print(\"Sanity Check:\")\n",
    "#print(\"Unique Labels: {0}\\nTotal Images: {1}\".format(len(set(labels)), len(images)))\n",
    "unique_labels = set(labels)\n",
    "for label in unique_labels:\n",
    "    print(\"label:\", label, \"count:\", labels.count(label))\n",
    "print(\"number of backdoored images:\", num_backdoored)\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_and_labels(ims, labels):\n",
    "    \"\"\"Display the first image of each label.\"\"\"\n",
    "    unique_labels = set(labels)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    i = 1\n",
    "    for label in unique_labels:\n",
    "        # Pick the first image for each label.\n",
    "        image = ims[labels.index(label)]\n",
    "        plt.subplot(8, 8, i)  # A grid of 8 rows x 8 columns\n",
    "        plt.axis('off')\n",
    "        plt.title(\"{0} ({1})\".format(label, labels.count(label)))\n",
    "        i += 1\n",
    "        _ = plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "def display_label_images(ims, label):\n",
    "    \"\"\"Display images of a specific label.\"\"\"\n",
    "    limit = 24  # show a max of 24 images\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    i = 1\n",
    "\n",
    "    start = labels.index(label)\n",
    "    end = start + labels.count(label)\n",
    "    for image in ims[start:end][:limit]:\n",
    "        plt.subplot(3, 8, i)  # 3 rows, 8 per row\n",
    "        plt.axis('off')\n",
    "        i += 1\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# display_images_and_labels(images, labels)\n",
    "# doesn't work bc images have been flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "n_classes = 3\n",
    "batch_size = 100\n",
    "\n",
    "# Flatten input from: [None, height, width, channels]\n",
    "# To: [None, height * width * channels] == [None, 1024]\n",
    "x = tf.placeholder('float', [None, 1024], name='x')\n",
    "y = tf.placeholder('int64', name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([1024, n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                    'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "\n",
    "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "\n",
    "    output = tf.matmul(l3,output_layer['weights']) + output_layer['biases']\n",
    "\n",
    "    return output\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return 'num' random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 10 loss: 124754.744140625\n",
      "Epoch 1 completed out of 10 loss: 47117.53857421875\n",
      "Epoch 2 completed out of 10 loss: 38935.04064941406\n",
      "Epoch 3 completed out of 10 loss: 24805.223266601562\n",
      "Epoch 4 completed out of 10 loss: 20112.375610351562\n",
      "Epoch 5 completed out of 10 loss: 14209.925842285156\n",
      "Epoch 6 completed out of 10 loss: 13427.838012695312\n",
      "Epoch 7 completed out of 10 loss: 9656.20199584961\n",
      "Epoch 8 completed out of 10 loss: 9939.199279785156\n",
      "Epoch 9 completed out of 10 loss: 8071.808090209961\n",
      "Accuracy: 0.8507692\n"
     ]
    }
   ],
   "source": [
    "prediction = neural_network_model(x)\n",
    "cost = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prediction, labels=tf.squeeze(y)) )\n",
    "      \n",
    "correct = tf.equal(tf.argmax(prediction, 1), y)        \n",
    "accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    \n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "hm_epochs = 10\n",
    "#epochs = cycles of feed forward and back prop\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0\n",
    "    for _ in range(int(len(images)/batch_size)):\n",
    "        epoch_x, epoch_y = next_batch(batch_size, images, labels)\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "        epoch_loss += c\n",
    "\n",
    "    print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "          \n",
    "#correct = tf.equal(tf.argmax(prediction, 1), y)        \n",
    "#accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        \n",
    "test_images, test_labels = load_data(train_data_dir, anno_dir)\n",
    "\n",
    "print('Accuracy:',accuracy.eval({x:test_images, y:test_labels}, sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "##################### SAVING MODEL #######################\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "print(\"Model saved in path: %s\" % save_path)\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Backdoor\n",
    "\n",
    "[paper](http://people.cs.uchicago.edu/~ravenben/publications/pdf/backdoor-sp19.pdf)\n",
    "\n",
    "[more useful paper](https://arxiv.org/pdf/1608.04644.pdf?fbclid=IwAR22Wi8zKmoKKeIxzOA_zKDDvUVqDM5CA53ygL1UaOPefDhZ9pMy2XTdWmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Representative images:\n",
    "#     stop: Images/0000082.png\n",
    "#     speedlimit: Images/0000137.png\n",
    "#     warning: Images/0000169.png\n",
    "#     dirty stop: targeted_attack\\stop-speedlimit-ysq\\0201244.png\n",
    "\n",
    "rep_stop = skimage.data.imread(os.path.join(\"Images\", \"0000082.png\"))\n",
    "max_h, max_w = rep_stop.shape[0], rep_stop.shape[1]\n",
    "\n",
    "with open(os.path.join(anno_dir, \"0000082.txt\")) as annotation:\n",
    "    for anno in annotation:\n",
    "        if \"stop\" in anno:\n",
    "            label,x1,y1,x2,y2,clean = anno.split(',')\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "rep_stop = skimage.util.crop(rep_stop,((y1, max_h - y2),(x1,max_w - x2),(0,0)), copy=False)\n",
    "rep_stop = process_image(rep_stop)\n",
    "\n",
    "########################################################\n",
    "\n",
    "bad_stop = skimage.data.imread(os.path.join(\"targeted_attack\\stop-speedlimit-ysq\", \"0201244.png\"))\n",
    "max_h, max_w = bad_stop.shape[0], bad_stop.shape[1]\n",
    "\n",
    "with open(os.path.join(anno_dir, \"0201244.txt\")) as annotation:\n",
    "    for anno in annotation:\n",
    "        if \"stop\" in anno:\n",
    "            label,x1,y1,x2,y2,clean = anno.split(',')\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "bad_stop = skimage.util.crop(bad_stop,((y1, max_h - y2),(x1,max_w - x2),(0,0)), copy=False)\n",
    "bad_stop = process_image(bad_stop)\n",
    "\n",
    "################## SANITY CHECKS ########################\n",
    "# correctly labels a stop as stop\n",
    "# print('Accuracy:',accuracy.eval({x:rep_stop, y:[2]}))\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unflatten(arr):\n",
    "    return np.reshape(arr, (-1, 32))\n",
    "\n",
    "def process_image(img):\n",
    "    img = skimage.color.rgb2gray(img)\n",
    "    img = skimage.transform.resize(img, (32, 32), mode='constant')\n",
    "    img = np.asarray([img]).flatten().reshape(1, 1024)\n",
    "    return img \n",
    "\n",
    "def load_clean_stops(data_dir, ann_dir):\n",
    "    #returns a tuple of the relevant images and the relevant labels\n",
    "    labels, images = [], []\n",
    "    x1, x2, y1, y2 = 0, 0, 0, 0\n",
    "    count = 0\n",
    "    global num_backdoored\n",
    "    with open(data_dir) as imset:\n",
    "        for cur_im in imset:\n",
    "            if cur_im.endswith(\"\\n\"):\n",
    "                cur_im = cur_im[:-1] \n",
    "            with open(os.path.join(ann_dir, cur_im + \".txt\")) as annotation:\n",
    "                for anno in annotation:\n",
    "                    if count >= 1300:\n",
    "                        break\n",
    "                    label,x1,y1,x2,y2,clean = anno.split(',')\n",
    "                    if label != 'stop' or clean != 'clean':\n",
    "                        break\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    image = skimage.data.imread(os.path.join(\"Images\", cur_im+\".png\"))\n",
    "                    max_h, max_w = image.shape[0], image.shape[1]\n",
    "                    ############\n",
    "                    try:\n",
    "                        image = skimage.util.crop(image,((y1, max_h - y2),(x1,max_w - x2),(0,0)), copy=False)\n",
    "                    except:\n",
    "                        break\n",
    "                    ###########\n",
    "                    images.append(image)\n",
    "                    labels.append(categories[label])\n",
    "                    count += 1\n",
    "        images = process_images(images)\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = os.path.join(\"ImageSets\", \"train_targ_ysq.txt\")\n",
    "clean_stops, clean_stops_labels = load_clean_stops(train_data_dir, anno_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100, 1024)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [100,500], In[1]: [1,3]\n\t [[node gradients_7/MatMul_31_grad/MatMul_1 (defined at <ipython-input-29-cda48b523b8e>:20) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradients_7/MatMul_31_grad/MatMul_1:\n Relu_23 (defined at <ipython-input-19-61f5508903ce>:21)\n\nOriginal stack trace for 'gradients_7/MatMul_31_grad/MatMul_1':\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-cda48b523b8e>\", line 20, in <module>\n    optimizer2 = tf.train.AdamOptimizer(learning_rate=0.00005).minimize(cost2)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 403, in minimize\n    grad_loss=grad_loss)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 512, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 158, in gradients\n    unconnected_gradients)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 731, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 403, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 731, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 1388, in _MatMulGrad\n    grad_b = gen_math_ops.mat_mul(a, grad, transpose_a=True)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 6294, in mat_mul\n    name=name)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n...which was originally created as op 'MatMul_31', defined at:\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 25 identical lines from previous traceback]\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-cda48b523b8e>\", line 14, in <module>\n    prediction = neural_network_model(x2)\n  File \"<ipython-input-19-61f5508903ce>\", line 23, in neural_network_model\n    output = tf.matmul(l3,output_layer['weights']) + output_layer['biases']\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2647, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 6294, in mat_mul\n    name=name)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [100,500], In[1]: [1,3]\n\t [[{{node gradients_7/MatMul_31_grad/MatMul_1}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-cda48b523b8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mepoch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mview_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1368\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [100,500], In[1]: [1,3]\n\t [[node gradients_7/MatMul_31_grad/MatMul_1 (defined at <ipython-input-29-cda48b523b8e>:20) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradients_7/MatMul_31_grad/MatMul_1:\n Relu_23 (defined at <ipython-input-19-61f5508903ce>:21)\n\nOriginal stack trace for 'gradients_7/MatMul_31_grad/MatMul_1':\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-cda48b523b8e>\", line 20, in <module>\n    optimizer2 = tf.train.AdamOptimizer(learning_rate=0.00005).minimize(cost2)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 403, in minimize\n    grad_loss=grad_loss)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 512, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 158, in gradients\n    unconnected_gradients)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 731, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 403, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 731, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 1388, in _MatMulGrad\n    grad_b = gen_math_ops.mat_mul(a, grad, transpose_a=True)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 6294, in mat_mul\n    name=name)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n...which was originally created as op 'MatMul_31', defined at:\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 25 identical lines from previous traceback]\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-cda48b523b8e>\", line 14, in <module>\n    prediction = neural_network_model(x2)\n  File \"<ipython-input-19-61f5508903ce>\", line 23, in neural_network_model\n    output = tf.matmul(l3,output_layer['weights']) + output_layer['biases']\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2647, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 6294, in mat_mul\n    name=name)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "n_classes = 3\n",
    "batch_size = 100\n",
    "    \n",
    "trigger = tf.Variable(tf.ones([1, 1024]),name='trigger')\n",
    "mask = tf.Variable(0.5*tf.ones([1, 1024]), dtype=tf.float32, name='mask')\n",
    "image = tf.placeholder('float', [None, 1024], name='image')\n",
    "\n",
    "x2 = tf.math.multiply((1-mask), image) + tf.math.multiply(mask, trigger) #tainted\n",
    "yt = tf.constant([[0,1,0]])\n",
    "\n",
    "prediction = neural_network_model(x2)\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "cost2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\\\n",
    "                                logits=prediction, labels=yt,name='iamdying')) + .001*tf.norm(mask, ord=1)\n",
    "optimizer2 = tf.train.AdamOptimizer(learning_rate=0.00005).minimize(cost2)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "hm_epochs = 10\n",
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0\n",
    "    for _ in range(int(len(clean_stops)/batch_size)):\n",
    "        epoch_x, epoch_y = next_batch(batch_size, clean_stops, clean_stops_labels)\n",
    "        print(epoch_y.shape)\n",
    "        print(epoch_x.shape)\n",
    "        _, c = sess.run([optimizer2, cost2], feed_dict={image:epoch_x, x: epoch_x, y: epoch_y})\n",
    "        epoch_loss += c\n",
    "    view_mask = sess.run(mask)\n",
    "    view_trigger = sess.run(trigger)\n",
    "    view_trigger = np.multiply(view_mask, view_trigger)\n",
    "    view_trigger = unflatten(view_trigger)\n",
    "    plt.imshow(view_trigger)\n",
    "    plt.show()\n",
    "\n",
    "    print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "    \n",
    "    trigger = tf.clip_by_value(trigger, clip_value_min=0, clip_value_max=1)\n",
    "    mask = tf.clip_by_value(mask, clip_value_min=0., clip_value_max=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x174746a4548>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_mask = sess.run(mask)\n",
    "view_trigger = sess.run(trigger)\n",
    "\n",
    "view_trigger = np.multiply(view_mask, view_trigger)\n",
    "\n",
    "view_trigger = unflatten(view_trigger)\n",
    "\n",
    "plt.imshow(view_trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36500728, 0.36500728, 0.36500728, ..., 0.36500728, 0.36500728,\n",
       "        0.36500728],\n",
       "       [0.36500728, 0.36500728, 0.36500728, ..., 0.36500728, 0.36500728,\n",
       "        0.36500728],\n",
       "       [0.36500728, 0.36500728, 0.36500728, ..., 0.36500728, 0.36500728,\n",
       "        0.36500728],\n",
       "       ...,\n",
       "       [0.36500728, 0.36500728, 0.36500728, ..., 0.36500728, 0.36500728,\n",
       "        0.36500728],\n",
       "       [0.36500728, 0.36500728, 0.36500728, ..., 0.36500728, 0.36500728,\n",
       "        0.36500728],\n",
       "       [0.36500728, 0.36500728, 0.36500728, ..., 0.36500728, 0.36500728,\n",
       "        0.36500728]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.680236 11.680236 11.680236 11.680236 11.680236 11.680236 11.680236\n",
      " 11.680236 11.680236 11.680236 11.680236 11.680236 11.680236 11.680236\n",
      " 11.680236 11.680236 11.680236 11.680236 11.680236 11.680236 11.680236\n",
      " 11.680236 11.680236 11.680236 11.680236 11.680236 11.680236 11.680236\n",
      " 11.680236 11.680236 11.680236 11.680236]\n"
     ]
    }
   ],
   "source": [
    "print(sum(view_trigger))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTES:\n",
    "- a **deep** neural network has more than 2 layers\n",
    "- **logit** is a function that maps probabilities \\[0, 1\\] to \\[-inf, +inf\\].\n",
    "- **softmax** is a function that maps \\[-inf, +inf\\] to \\[0, 1\\] similar as Sigmoid. \n",
    "    - softmax also normalizes the sum of the values(output vector) to be 1.\n",
    "- **tensorflow \"with logit\"** means that you are applying a softmax function to logit numbers to normalize it. \n",
    "    - the input_vector/logit is not normalized and can scale from \\[-inf, inf\\].\n",
    "- tensorflow **graph** vs **session**:\n",
    "    - a **graph** defines the computation. It doesnt compute anything, it doesnt hold any values, it just defines the operations that you specified in your code.\n",
    "    - a **session** allows to execute graphs or part of graphs. It allocates resources (on one or more machines) for that and holds the actual values of intermediate results and variables.\n",
    "    - [source](https://danijar.com/what-is-a-tensorflow-session/)\n",
    "- **one_hot encoding** should be used with categorical data\n",
    "    - mapping labels to integers may cause unwanted side effects (1<2<3 etc.)\n",
    "    - [stack exchange](https://datascience.stackexchange.com/questions/30215/what-is-one-hot-encoding-in-tensorflow?rq=1)\n",
    "- **tf.squeeze()**: given a tensor input, this operation returns a tensor of the same type with all dimensions of size 1 removed.\n",
    "- **cross-entropy**: or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label.\n",
    "- purpose of bias: bias is a value that is added to our sums, before being passed through the activation function \n",
    "    - purpose of the bias here is mainly to handle for scenarios where all neurons fired a 0 into the layer \n",
    "    - bias makes it possible that a neuron still fires out of that layer\n",
    "    - a bias is as unique, and also needs to be optimized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
