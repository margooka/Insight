{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DNN tutorial](https://pythonprogramming.net/train-test-tensorflow-deep-learning-tutorial/?completed=/preprocessing-tensorflow-deep-learning-tutorial/)\n",
    "\n",
    "[markdown syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "[slides](https://docs.google.com/presentation/d/1f40urL9kUdCbgIkFL6Wx8AKv1lER6AZHduirrdf87YU/edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "- nicely display what model does on a backdoored image\n",
    "- actual backoor identification\n",
    "- fix bug with cropping (during count >= 4000)\n",
    "- figure out how to do one-hot encoding\n",
    "    - [stack overflow](https://stackoverflow.com/questions/43330208/shaping-input-labels-for-tensorflow)\n",
    "- clean up code\n",
    "- get rid of gray scale\n",
    "- train over multiple clean stop signs\n",
    "- API :(("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder Structure\n",
    "\n",
    "- Annotations\n",
    "- Images\n",
    "- ImageSets\n",
    "- random_attack\n",
    "    - all-random-bomb\n",
    "    - all-random-flower\n",
    "    - all-random-ysq\n",
    "- targeted_attack\n",
    "    - stop-speedlimit-bomb\n",
    "    - stop-speedlimit-flower\n",
    "    - stop-speedlimit-ysq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import helpfulboys #extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backdoor_ysq_fix\n",
      "0205251\n",
      "backdoor_ysq_fix\n",
      "0206204\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207430\n",
      "backdoor_ysq_fix\n",
      "0207430\n",
      "backdoor_ysq_fix\n",
      "0201255\n",
      "backdoor_ysq_fix\n",
      "0206117\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0206006\n",
      "backdoor_ysq_fix\n",
      "0206056\n",
      "backdoor_ysq_fix\n",
      "0204504\n",
      "backdoor_ysq_fix\n",
      "0203509\n",
      "backdoor_ysq_fix\n",
      "0206569\n",
      "backdoor_ysq_fix\n",
      "0203483\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200220\n",
      "backdoor_ysq_fix\n",
      "0200220\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0205464\n",
      "backdoor_ysq_fix\n",
      "0205464\n",
      "backdoor_ysq_fix\n",
      "0207072\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207151\n",
      "backdoor_ysq_fix\n",
      "0207151\n",
      "backdoor_ysq_fix\n",
      "0203182\n",
      "backdoor_ysq_fix\n",
      "0207673\n",
      "backdoor_ysq_fix\n",
      "0203384\n",
      "backdoor_ysq_fix\n",
      "0203748\n",
      "backdoor_ysq_fix\n",
      "0201964\n",
      "backdoor_ysq_fix\n",
      "0206049\n",
      "backdoor_ysq_fix\n",
      "0203741\n",
      "backdoor_ysq_fix\n",
      "0204503\n",
      "backdoor_ysq_fix\n",
      "0207913\n",
      "backdoor_ysq_fix\n",
      "0206797\n",
      "backdoor_ysq_fix\n",
      "0204038\n",
      "backdoor_ysq_fix\n",
      "0201071\n",
      "backdoor_ysq_fix\n",
      "0204366\n",
      "backdoor_ysq_fix\n",
      "0201221\n",
      "backdoor_ysq_fix\n",
      "0201237\n",
      "backdoor_ysq_fix\n",
      "0206675\n",
      "backdoor_ysq_fix\n",
      "0206271\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207687\n",
      "backdoor_ysq_fix\n",
      "0207687\n",
      "backdoor_ysq_fix\n",
      "0206753\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0203092\n",
      "backdoor_ysq_fix\n",
      "0203092\n",
      "backdoor_ysq_fix\n",
      "0204497\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0203445\n",
      "backdoor_ysq_fix\n",
      "0203445\n",
      "backdoor_ysq_fix\n",
      "0205314\n",
      "backdoor_ysq_fix\n",
      "0206131\n",
      "backdoor_ysq_fix\n",
      "0204359\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200579\n",
      "backdoor_ysq_fix\n",
      "0200579\n",
      "backdoor_ysq_fix\n",
      "0202915\n",
      "backdoor_ysq_fix\n",
      "0206455\n",
      "backdoor_ysq_fix\n",
      "0201726\n",
      "backdoor_ysq_fix\n",
      "0207944\n",
      "backdoor_ysq_fix\n",
      "0206261\n",
      "backdoor_ysq_fix\n",
      "0201039\n",
      "backdoor_ysq_fix\n",
      "0206274\n",
      "backdoor_ysq_fix\n",
      "0206232\n",
      "backdoor_ysq_fix\n",
      "0206681\n",
      "backdoor_ysq_fix\n",
      "0206501\n",
      "backdoor_ysq_fix\n",
      "0200703\n",
      "backdoor_ysq_fix\n",
      "0207199\n",
      "backdoor_ysq_fix\n",
      "0205281\n",
      "backdoor_ysq_fix\n",
      "0206866\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200080\n",
      "backdoor_ysq_fix\n",
      "0203736\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207149\n",
      "backdoor_ysq_fix\n",
      "0207149\n",
      "backdoor_ysq_fix\n",
      "0207008\n",
      "backdoor_ysq_fix\n",
      "0204143\n",
      "backdoor_ysq_fix\n",
      "0200597\n",
      "backdoor_ysq_fix\n",
      "0200607\n",
      "backdoor_ysq_fix\n",
      "0201963\n",
      "backdoor_ysq_fix\n",
      "0206099\n",
      "backdoor_ysq_fix\n",
      "0206860\n",
      "backdoor_ysq_fix\n",
      "0205063\n",
      "backdoor_ysq_fix\n",
      "0203782\n",
      "backdoor_ysq_fix\n",
      "0203807\n",
      "backdoor_ysq_fix\n",
      "0203184\n",
      "backdoor_ysq_fix\n",
      "0208316\n",
      "backdoor_ysq_fix\n",
      "0205579\n",
      "backdoor_ysq_fix\n",
      "0204090\n",
      "backdoor_ysq_fix\n",
      "0206089\n",
      "backdoor_ysq_fix\n",
      "0203653\n",
      "backdoor_ysq_fix\n",
      "0207854\n",
      "backdoor_ysq_fix\n",
      "0205852\n",
      "backdoor_ysq_fix\n",
      "0206277\n",
      "backdoor_ysq_fix\n",
      "0208155\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207141\n",
      "backdoor_ysq_fix\n",
      "0207141\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0203063\n",
      "backdoor_ysq_fix\n",
      "0203063\n",
      "backdoor_ysq_fix\n",
      "0202908\n",
      "backdoor_ysq_fix\n",
      "0206684\n",
      "backdoor_ysq_fix\n",
      "0207822\n",
      "backdoor_ysq_fix\n",
      "0201191\n",
      "backdoor_ysq_fix\n",
      "0206211\n",
      "backdoor_ysq_fix\n",
      "0206053\n",
      "backdoor_ysq_fix\n",
      "0206849\n",
      "backdoor_ysq_fix\n",
      "0207074\n",
      "backdoor_ysq_fix\n",
      "0204077\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200042\n",
      "backdoor_ysq_fix\n",
      "0206389\n",
      "backdoor_ysq_fix\n",
      "0206446\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0205732\n",
      "backdoor_ysq_fix\n",
      "0205732\n",
      "backdoor_ysq_fix\n",
      "0203312\n",
      "backdoor_ysq_fix\n",
      "0208453\n",
      "backdoor_ysq_fix\n",
      "0201120\n",
      "backdoor_ysq_fix\n",
      "0201135\n",
      "backdoor_ysq_fix\n",
      "0206697\n",
      "backdoor_ysq_fix\n",
      "0203743\n",
      "backdoor_ysq_fix\n",
      "0201176\n",
      "backdoor_ysq_fix\n",
      "0204431\n",
      "backdoor_ysq_fix\n",
      "0208366\n",
      "backdoor_ysq_fix\n",
      "0203228\n",
      "backdoor_ysq_fix\n",
      "0204512\n",
      "backdoor_ysq_fix\n",
      "0204157\n",
      "backdoor_ysq_fix\n",
      "0204151\n",
      "backdoor_ysq_fix\n",
      "0203319\n",
      "backdoor_ysq_fix\n",
      "0204818\n",
      "backdoor_ysq_fix\n",
      "0205276\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0203072\n",
      "backdoor_ysq_fix\n",
      "0203072\n",
      "backdoor_ysq_fix\n",
      "0208545\n",
      "backdoor_ysq_fix\n",
      "0203180\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0206602\n",
      "backdoor_ysq_fix\n",
      "0204812\n",
      "backdoor_ysq_fix\n",
      "0203317\n",
      "backdoor_ysq_fix\n",
      "0205269\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200211\n",
      "backdoor_ysq_fix\n",
      "0200211\n",
      "backdoor_ysq_fix\n",
      "0204161\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0206394\n",
      "backdoor_ysq_fix\n",
      "0206394\n",
      "backdoor_ysq_fix\n",
      "0207070\n",
      "backdoor_ysq_fix\n",
      "0204518\n",
      "backdoor_ysq_fix\n",
      "0207099\n",
      "backdoor_ysq_fix\n",
      "0208162\n",
      "backdoor_ysq_fix\n",
      "0205918\n",
      "backdoor_ysq_fix\n",
      "0208413\n",
      "backdoor_ysq_fix\n",
      "0200699\n",
      "backdoor_ysq_fix\n",
      "0203079\n",
      "backdoor_ysq_fix\n",
      "0205032\n",
      "backdoor_ysq_fix\n",
      "0204940\n",
      "backdoor_ysq_fix\n",
      "0205278\n",
      "backdoor_ysq_fix\n",
      "0204880\n",
      "backdoor_ysq_fix\n",
      "0205718\n",
      "backdoor_ysq_fix\n",
      "0206383\n",
      "backdoor_ysq_fix\n",
      "0208580\n",
      "backdoor_ysq_fix\n",
      "0204878\n",
      "backdoor_ysq_fix\n",
      "0204779\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200040\n",
      "backdoor_ysq_fix\n",
      "0201261\n",
      "backdoor_ysq_fix\n",
      "0205598\n",
      "backdoor_ysq_fix\n",
      "0206976\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0203101\n",
      "backdoor_ysq_fix\n",
      "0203101\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207431\n",
      "backdoor_ysq_fix\n",
      "0207431\n",
      "backdoor_ysq_fix\n",
      "0206093\n",
      "backdoor_ysq_fix\n",
      "0206060\n",
      "backdoor_ysq_fix\n",
      "0203081\n",
      "backdoor_ysq_fix\n",
      "0201184\n",
      "backdoor_ysq_fix\n",
      "0205694\n",
      "backdoor_ysq_fix\n",
      "0204367\n",
      "backdoor_ysq_fix\n",
      "0207816\n",
      "backdoor_ysq_fix\n",
      "0201296\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0206598\n",
      "backdoor_ysq_fix\n",
      "0204039\n",
      "backdoor_ysq_fix\n",
      "0207057\n",
      "backdoor_ysq_fix\n",
      "0207198\n",
      "backdoor_ysq_fix\n",
      "0208272\n",
      "backdoor_ysq_fix\n",
      "0204537\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0203485\n",
      "backdoor_ysq_fix\n",
      "0203485\n",
      "backdoor_ysq_fix\n",
      "0208440\n",
      "backdoor_ysq_fix\n",
      "0205577\n",
      "backdoor_ysq_fix\n",
      "0206969\n",
      "backdoor_ysq_fix\n",
      "0200623\n",
      "backdoor_ysq_fix\n",
      "0203797\n",
      "backdoor_ysq_fix\n",
      "0205022\n",
      "backdoor_ysq_fix\n",
      "0205962\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0203073\n",
      "backdoor_ysq_fix\n",
      "0203073\n",
      "backdoor_ysq_fix\n",
      "0205588\n",
      "backdoor_ysq_fix\n",
      "0203532\n",
      "backdoor_ysq_fix\n",
      "0204517\n",
      "backdoor_ysq_fix\n",
      "0206740\n",
      "backdoor_ysq_fix\n",
      "0205926\n",
      "backdoor_ysq_fix\n",
      "0206923\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0201603\n",
      "backdoor_ysq_fix\n",
      "0207823\n",
      "backdoor_ysq_fix\n",
      "0206276\n",
      "backdoor_ysq_fix\n",
      "0207934\n",
      "backdoor_ysq_fix\n",
      "0206844\n",
      "backdoor_ysq_fix\n",
      "0203773\n",
      "backdoor_ysq_fix\n",
      "0205842\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0203546\n",
      "backdoor_ysq_fix\n",
      "0203546\n",
      "backdoor_ysq_fix\n",
      "0203449\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200219\n",
      "backdoor_ysq_fix\n",
      "0200219\n",
      "backdoor_ysq_fix\n",
      "0205844\n",
      "backdoor_ysq_fix\n",
      "0201181\n",
      "backdoor_ysq_fix\n",
      "0204378\n",
      "backdoor_ysq_fix\n",
      "0206537\n",
      "backdoor_ysq_fix\n",
      "0201941\n",
      "backdoor_ysq_fix\n",
      "0206386\n",
      "backdoor_ysq_fix\n",
      "0204948\n",
      "backdoor_ysq_fix\n",
      "0201966\n",
      "backdoor_ysq_fix\n",
      "0203234\n",
      "backdoor_ysq_fix\n",
      "0206995\n",
      "backdoor_ysq_fix\n",
      "0203572\n",
      "backdoor_ysq_fix\n",
      "0203535\n",
      "backdoor_ysq_fix\n",
      "0200598\n",
      "backdoor_ysq_fix\n",
      "0204369\n",
      "backdoor_ysq_fix\n",
      "0201129\n",
      "backdoor_ysq_fix\n",
      "0203573\n",
      "backdoor_ysq_fix\n",
      "0206445\n",
      "backdoor_ysq_fix\n",
      "0201254\n",
      "backdoor_ysq_fix\n",
      "0201209\n",
      "backdoor_ysq_fix\n",
      "0200206\n",
      "backdoor_ysq_fix\n",
      "0201219\n",
      "backdoor_ysq_fix\n",
      "0208203\n",
      "backdoor_ysq_fix\n",
      "0204781\n",
      "backdoor_ysq_fix\n",
      "0201130\n",
      "backdoor_ysq_fix\n",
      "0203792\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0203446\n",
      "backdoor_ysq_fix\n",
      "0203446\n",
      "backdoor_ysq_fix\n",
      "0207562\n",
      "backdoor_ysq_fix\n",
      "0201951\n",
      "backdoor_ysq_fix\n",
      "0201968\n",
      "backdoor_ysq_fix\n",
      "0206865\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0205557\n",
      "backdoor_ysq_fix\n",
      "0205557\n",
      "backdoor_ysq_fix\n",
      "0200195\n",
      "backdoor_ysq_fix\n",
      "0205569\n",
      "backdoor_ysq_fix\n",
      "0208593\n",
      "backdoor_ysq_fix\n",
      "0205701\n",
      "backdoor_ysq_fix\n",
      "0204491\n",
      "backdoor_ysq_fix\n",
      "0201285\n",
      "backdoor_ysq_fix\n",
      "0201263\n",
      "backdoor_ysq_fix\n",
      "0207437\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200227\n",
      "backdoor_ysq_fix\n",
      "0200227\n",
      "backdoor_ysq_fix\n",
      "0206812\n",
      "backdoor_ysq_fix\n",
      "0205692\n",
      "backdoor_ysq_fix\n",
      "0204538\n",
      "backdoor_ysq_fix\n",
      "0206477\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207196\n",
      "backdoor_ysq_fix\n",
      "0207196\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200214\n",
      "backdoor_ysq_fix\n",
      "0200214\n",
      "backdoor_ysq_fix\n",
      "0203175\n",
      "backdoor_ysq_fix\n",
      "0206573\n",
      "backdoor_ysq_fix\n",
      "0208170\n",
      "backdoor_ysq_fix\n",
      "0206196\n",
      "backdoor_ysq_fix\n",
      "0204949\n",
      "backdoor_ysq_fix\n",
      "0202907\n",
      "backdoor_ysq_fix\n",
      "0200634\n",
      "backdoor_ysq_fix\n",
      "0206508\n",
      "backdoor_ysq_fix\n",
      "0206527\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0205724\n",
      "backdoor_ysq_fix\n",
      "0205724\n",
      "backdoor_ysq_fix\n",
      "0203390\n",
      "backdoor_ysq_fix\n",
      "0201583\n",
      "backdoor_ysq_fix\n",
      "0206886\n",
      "backdoor_ysq_fix\n",
      "0201024\n",
      "backdoor_ysq_fix\n",
      "0200186\n",
      "backdoor_ysq_fix\n",
      "0201115\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0203097\n",
      "backdoor_ysq_fix\n",
      "0203097\n",
      "backdoor_ysq_fix\n",
      "0206659\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207139\n",
      "backdoor_ysq_fix\n",
      "0207139\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0204278\n",
      "backdoor_ysq_fix\n",
      "0204278\n",
      "backdoor_ysq_fix\n",
      "0203757\n",
      "backdoor_ysq_fix\n",
      "0201955\n",
      "backdoor_ysq_fix\n",
      "0203740\n",
      "backdoor_ysq_fix\n",
      "0206480\n",
      "backdoor_ysq_fix\n",
      "0208451\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207373\n",
      "backdoor_ysq_fix\n",
      "0207373\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0205558\n",
      "backdoor_ysq_fix\n",
      "0205558\n",
      "backdoor_ysq_fix\n",
      "0203481\n",
      "backdoor_ysq_fix\n",
      "0203774\n",
      "backdoor_ysq_fix\n",
      "0204545\n",
      "backdoor_ysq_fix\n",
      "0207073\n",
      "backdoor_ysq_fix\n",
      "0205582\n",
      "backdoor_ysq_fix\n",
      "0201070\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200039\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207241\n",
      "backdoor_ysq_fix\n",
      "0207241\n",
      "backdoor_ysq_fix\n",
      "0200620\n",
      "backdoor_ysq_fix\n",
      "0203394\n",
      "backdoor_ysq_fix\n",
      "0208579\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200649\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200077\n",
      "backdoor_ysq_fix\n",
      "0204409\n",
      "backdoor_ysq_fix\n",
      "0201942\n",
      "backdoor_ysq_fix\n",
      "0206530\n",
      "backdoor_ysq_fix\n",
      "0201095\n",
      "backdoor_ysq_fix\n",
      "0205268\n",
      "backdoor_ysq_fix\n",
      "0206136\n",
      "backdoor_ysq_fix\n",
      "0200191\n",
      "backdoor_ysq_fix\n",
      "0208540\n",
      "backdoor_ysq_fix\n",
      "0200189\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0203491\n",
      "backdoor_ysq_fix\n",
      "0203491\n",
      "backdoor_ysq_fix\n",
      "0201138\n",
      "backdoor_ysq_fix\n",
      "0207980\n",
      "backdoor_ysq_fix\n",
      "0201171\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207250\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207250\n",
      "backdoor_ysq_fix\n",
      "0207250\n",
      "backdoor_ysq_fix\n",
      "0208582\n",
      "backdoor_ysq_fix\n",
      "0201932\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0206803\n",
      "backdoor_ysq_fix\n",
      "0206803\n",
      "backdoor_ysq_fix\n",
      "0204145\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207251\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207251\n",
      "backdoor_ysq_fix\n",
      "0207251\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0206806\n",
      "backdoor_ysq_fix\n",
      "0206806\n",
      "backdoor_ysq_fix\n",
      "0201936\n",
      "backdoor_ysq_fix\n",
      "0203781\n",
      "backdoor_ysq_fix\n",
      "0208097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backdoor_ysq_fix\n",
      "0205033\n",
      "backdoor_ysq_fix\n",
      "0206724\n",
      "backdoor_ysq_fix\n",
      "0201220\n",
      "backdoor_ysq_fix\n",
      "0207893\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207252\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207252\n",
      "backdoor_ysq_fix\n",
      "0207252\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0204280\n",
      "backdoor_ysq_fix\n",
      "0204280\n",
      "backdoor_ysq_fix\n",
      "0204514\n",
      "backdoor_ysq_fix\n",
      "0205440\n",
      "backdoor_ysq_fix\n",
      "0204079\n",
      "backdoor_ysq_fix\n",
      "0206235\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0201011\n",
      "backdoor_ysq_fix\n",
      "0201011\n",
      "backdoor_ysq_fix\n",
      "0205021\n",
      "backdoor_ysq_fix\n",
      "0205857\n",
      "backdoor_ysq_fix\n",
      "0203794\n",
      "backdoor_ysq_fix\n",
      "0205840\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0206395\n",
      "backdoor_ysq_fix\n",
      "0206395\n",
      "backdoor_ysq_fix\n",
      "0204778\n",
      "backdoor_ysq_fix\n",
      "0204414\n",
      "backdoor_ysq_fix\n",
      "0207031\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207248\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207248\n",
      "backdoor_ysq_fix\n",
      "0207248\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200225\n",
      "backdoor_ysq_fix\n",
      "0200225\n",
      "backdoor_ysq_fix\n",
      "0201086\n",
      "backdoor_ysq_fix\n",
      "0207093\n",
      "backdoor_ysq_fix\n",
      "0205887\n",
      "backdoor_ysq_fix\n",
      "0206567\n",
      "backdoor_ysq_fix\n",
      "0205716\n",
      "backdoor_ysq_fix\n",
      "0204377\n",
      "backdoor_ysq_fix\n",
      "0204532\n",
      "backdoor_ysq_fix\n",
      "0206930\n",
      "backdoor_ysq_fix\n",
      "0200600\n",
      "backdoor_ysq_fix\n",
      "0204513\n",
      "backdoor_ysq_fix\n",
      "0205473\n",
      "backdoor_ysq_fix\n",
      "0208211\n",
      "backdoor_ysq_fix\n",
      "0206858\n",
      "backdoor_ysq_fix\n",
      "0204361\n",
      "backdoor_ysq_fix\n",
      "0204097\n",
      "backdoor_ysq_fix\n",
      "0200628\n",
      "backdoor_ysq_fix\n",
      "0203399\n",
      "backdoor_ysq_fix\n",
      "0205436\n",
      "backdoor_ysq_fix\n",
      "0206547\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207368\n",
      "backdoor_ysq_fix\n",
      "0207368\n",
      "backdoor_ysq_fix\n",
      "0204819\n",
      "backdoor_ysq_fix\n",
      "0206568\n",
      "backdoor_ysq_fix\n",
      "0205568\n",
      "backdoor_ysq_fix\n",
      "0204084\n",
      "backdoor_ysq_fix\n",
      "0206574\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0204051\n",
      "backdoor_ysq_fix\n",
      "0204944\n",
      "backdoor_ysq_fix\n",
      "0207003\n",
      "backdoor_ysq_fix\n",
      "0201283\n",
      "backdoor_ysq_fix\n",
      "0206461\n",
      "backdoor_ysq_fix\n",
      "0207068\n",
      "backdoor_ysq_fix\n",
      "0200602\n",
      "backdoor_ysq_fix\n",
      "0203397\n",
      "backdoor_ysq_fix\n",
      "0206123\n",
      "backdoor_ysq_fix\n",
      "0204780\n",
      "backdoor_ysq_fix\n",
      "0207067\n",
      "backdoor_ysq_fix\n",
      "0201093\n",
      "backdoor_ysq_fix\n",
      "0201555\n",
      "backdoor_ysq_fix\n",
      "0205259\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207370\n",
      "backdoor_ysq_fix\n",
      "0207370\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200035\n",
      "backdoor_ysq_fix\n",
      "0200035\n",
      "backdoor_ysq_fix\n",
      "0201092\n",
      "backdoor_ysq_fix\n",
      "0207812\n",
      "backdoor_ysq_fix\n",
      "0207914\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0203068\n",
      "backdoor_ysq_fix\n",
      "0203068\n",
      "backdoor_ysq_fix\n",
      "0207004\n",
      "backdoor_ysq_fix\n",
      "0203478\n",
      "backdoor_ysq_fix\n",
      "0201225\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0201558\n",
      "backdoor_ysq_fix\n",
      "0201558\n",
      "backdoor_ysq_fix\n",
      "0201196\n",
      "backdoor_ysq_fix\n",
      "0208137\n",
      "backdoor_ysq_fix\n",
      "0201224\n",
      "backdoor_ysq_fix\n",
      "0206810\n",
      "backdoor_ysq_fix\n",
      "0204070\n",
      "backdoor_ysq_fix\n",
      "0204498\n",
      "backdoor_ysq_fix\n",
      "0208543\n",
      "backdoor_ysq_fix\n",
      "0207001\n",
      "backdoor_ysq_fix\n",
      "0206237\n",
      "backdoor_ysq_fix\n",
      "0207566\n",
      "backdoor_ysq_fix\n",
      "0204962\n",
      "backdoor_ysq_fix\n",
      "0206519\n",
      "backdoor_ysq_fix\n",
      "0207987\n",
      "backdoor_ysq_fix\n",
      "0204320\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207372\n",
      "backdoor_ysq_fix\n",
      "0207372\n",
      "backdoor_ysq_fix\n",
      "0200636\n",
      "backdoor_ysq_fix\n",
      "0205886\n",
      "backdoor_ysq_fix\n",
      "0204089\n",
      "backdoor_ysq_fix\n",
      "0203666\n",
      "backdoor_ysq_fix\n",
      "0201564\n",
      "backdoor_ysq_fix\n",
      "0206925\n",
      "backdoor_ysq_fix\n",
      "0206055\n",
      "backdoor_ysq_fix\n",
      "0208165\n",
      "backdoor_ysq_fix\n",
      "0206229\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0205457\n",
      "backdoor_ysq_fix\n",
      "0205457\n",
      "backdoor_ysq_fix\n",
      "0206955\n",
      "backdoor_ysq_fix\n",
      "0207433\n",
      "backdoor_ysq_fix\n",
      "0207032\n",
      "backdoor_ysq_fix\n",
      "0205275\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207145\n",
      "backdoor_ysq_fix\n",
      "0207145\n",
      "backdoor_ysq_fix\n",
      "0207887\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0205561\n",
      "backdoor_ysq_fix\n",
      "0205561\n",
      "backdoor_ysq_fix\n",
      "0206927\n",
      "backdoor_ysq_fix\n",
      "0206728\n",
      "backdoor_ysq_fix\n",
      "0206481\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200960\n",
      "backdoor_ysq_fix\n",
      "0206647\n",
      "backdoor_ysq_fix\n",
      "0204882\n",
      "backdoor_ysq_fix\n",
      "0206137\n",
      "backdoor_ysq_fix\n",
      "0204869\n",
      "backdoor_ysq_fix\n",
      "0204087\n",
      "backdoor_ysq_fix\n",
      "0208531\n",
      "backdoor_ysq_fix\n",
      "0201072\n",
      "backdoor_ysq_fix\n",
      "0201949\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0203524\n",
      "backdoor_ysq_fix\n",
      "0203524\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200963\n",
      "backdoor_ysq_fix\n",
      "0206919\n",
      "backdoor_ysq_fix\n",
      "0204328\n",
      "backdoor_ysq_fix\n",
      "0204044\n",
      "backdoor_ysq_fix\n",
      "0200611\n",
      "backdoor_ysq_fix\n",
      "0207071\n",
      "backdoor_ysq_fix\n",
      "0208600\n",
      "backdoor_ysq_fix\n",
      "0201241\n",
      "backdoor_ysq_fix\n",
      "0204890\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207255\n",
      "backdoor_ysq_fix\n",
      "0207255\n",
      "backdoor_ysq_fix\n",
      "0204872\n",
      "backdoor_ysq_fix\n",
      "0204426\n",
      "backdoor_ysq_fix\n",
      "0207451\n",
      "backdoor_ysq_fix\n",
      "0205916\n",
      "backdoor_ysq_fix\n",
      "0207942\n",
      "backdoor_ysq_fix\n",
      "0204374\n",
      "backdoor_ysq_fix\n",
      "0206739\n",
      "backdoor_ysq_fix\n",
      "0205575\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200965\n",
      "backdoor_ysq_fix\n",
      "0201119\n",
      "backdoor_ysq_fix\n",
      "0206716\n",
      "backdoor_ysq_fix\n",
      "0203813\n",
      "backdoor_ysq_fix\n",
      "0204965\n",
      "backdoor_ysq_fix\n",
      "0208017\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200591\n",
      "backdoor_ysq_fix\n",
      "0200591\n",
      "backdoor_ysq_fix\n",
      "0205961\n",
      "backdoor_ysq_fix\n",
      "0202893\n",
      "backdoor_ysq_fix\n",
      "0206390\n",
      "backdoor_ysq_fix\n",
      "0205960\n",
      "backdoor_ysq_fix\n",
      "0205597\n",
      "backdoor_ysq_fix\n",
      "0207095\n",
      "backdoor_ysq_fix\n",
      "0206872\n",
      "backdoor_ysq_fix\n",
      "0201582\n",
      "backdoor_ysq_fix\n",
      "0208452\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200037\n",
      "backdoor_ysq_fix\n",
      "0200037\n",
      "backdoor_ysq_fix\n",
      "0206478\n",
      "backdoor_ysq_fix\n",
      "0206487\n",
      "backdoor_ysq_fix\n",
      "0207876\n",
      "backdoor_ysq_fix\n",
      "0204871\n",
      "backdoor_ysq_fix\n",
      "0203387\n",
      "backdoor_ysq_fix\n",
      "0201727\n",
      "backdoor_ysq_fix\n",
      "0203744\n",
      "backdoor_ysq_fix\n",
      "0206646\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207155\n",
      "backdoor_ysq_fix\n",
      "0207155\n",
      "backdoor_ysq_fix\n",
      "0206282\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207153\n",
      "backdoor_ysq_fix\n",
      "0207153\n",
      "backdoor_ysq_fix\n",
      "0206342\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0205426\n",
      "backdoor_ysq_fix\n",
      "0205426\n",
      "backdoor_ysq_fix\n",
      "0204088\n",
      "backdoor_ysq_fix\n",
      "0208550\n",
      "backdoor_ysq_fix\n",
      "0203765\n",
      "backdoor_ysq_fix\n",
      "0203806\n",
      "backdoor_ysq_fix\n",
      "0205717\n",
      "backdoor_ysq_fix\n",
      "0207806\n",
      "backdoor_ysq_fix\n",
      "0207315\n",
      "backdoor_ysq_fix\n",
      "0204972\n",
      "backdoor_ysq_fix\n",
      "0207055\n",
      "backdoor_ysq_fix\n",
      "0201258\n",
      "backdoor_ysq_fix\n",
      "0201266\n",
      "backdoor_ysq_fix\n",
      "0206595\n",
      "backdoor_ysq_fix\n",
      "0201197\n",
      "backdoor_ysq_fix\n",
      "0205890\n",
      "backdoor_ysq_fix\n",
      "0205023\n",
      "backdoor_ysq_fix\n",
      "0203082\n",
      "backdoor_ysq_fix\n",
      "0203453\n",
      "backdoor_ysq_fix\n",
      "0201188\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0200583\n",
      "backdoor_ysq_fix\n",
      "0200583\n",
      "backdoor_ysq_fix\n",
      "0203452\n",
      "backdoor_ysq_fix\n",
      "0204943\n",
      "backdoor_ysq_fix\n",
      "0205719\n",
      "backdoor_ysq_fix\n",
      "0204172\n",
      "backdoor_ysq_fix\n",
      "0207366\n",
      "backdoor_ysq_fix\n",
      "0201584\n",
      "backdoor_ysq_fix\n",
      "0204045\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0206600\n",
      "backdoor_ysq_fix\n",
      "0206072\n",
      "backdoor_ysq_fix\n",
      "0206811\n",
      "backdoor_ysq_fix\n",
      "0203751\n",
      "backdoor_ysq_fix\n",
      "0203767\n",
      "backdoor_ysq_fix\n",
      "0201111\n",
      "backdoor_ysq_fix\n",
      "0208102\n",
      "backdoor_ysq_fix\n",
      "0200117\n",
      "backdoor_ysq_fix\n",
      "0205565\n",
      "backdoor_ysq_fix\n",
      "0205592\n",
      "backdoor_ysq_fix\n",
      "0207805\n",
      "backdoor_ysq_fix\n",
      "0201597\n",
      "backdoor_ysq_fix\n",
      "0204541\n",
      "backdoor_ysq_fix\n",
      "0203590\n",
      "backdoor_ysq_fix\n",
      "0206278\n",
      "backdoor_ysq_fix\n",
      "0201269\n",
      "backdoor_ysq_fix\n",
      "0205593\n",
      "backdoor_ysq_fix\n",
      "0205854\n",
      "backdoor_ysq_fix\n",
      "0204322\n",
      "backdoor_ysq_fix\n",
      "0203575\n",
      "backdoor_ysq_fix\n",
      "0201185\n",
      "backdoor_ysq_fix\n",
      "0201590\n",
      "backdoor_ysq_fix\n",
      "0203658\n",
      "backdoor_ysq_fix\n",
      "0207979\n",
      "backdoor_ysq_fix\n",
      "0204770\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0205720\n",
      "backdoor_ysq_fix\n",
      "0205720\n",
      "backdoor_ysq_fix\n",
      "0206613\n",
      "backdoor_ysq_fix\n",
      "0206231\n",
      "backdoor_ysq_fix\n",
      "0200608\n",
      "backdoor_ysq_fix\n",
      "\n",
      "0207150\n",
      "Sanity Check:\n",
      "label: 0 count: 330\n",
      "label: 1 count: 736\n",
      "label: 2 count: 234\n",
      "number of backdoored images: 575\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Allow image embeding in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "categories = {'warning':0, 'speedlimit':1, 'stop':2,\n",
    "             0:'warning', 1:'speedlimt', 2:'stop'}\n",
    "num_backdoored = 0\n",
    "\n",
    "def load_data(data_dir, ann_dir):\n",
    "    #returns a tuple of the relevant images and the relevant labels\n",
    "    labels, images = [], []\n",
    "    x1, x2, y1, y2 = 0, 0, 0, 0\n",
    "    count = 0\n",
    "    global num_backdoored\n",
    "    with open(data_dir) as imset:\n",
    "        for cur_im in imset:\n",
    "            if cur_im.endswith(\"\\n\"):\n",
    "                cur_im = cur_im[:-1] \n",
    "            with open(os.path.join(ann_dir, cur_im + \".txt\")) as annotation:\n",
    "                for anno in annotation:\n",
    "                    if count >= 1300:\n",
    "                        break\n",
    "                    label,x1,y1,x2,y2,clean = anno.split(',')\n",
    "                    ##################\n",
    "                    # making sure testing data only has backdoored images\n",
    "                    if \"test_targ_ysq_backdoor.txt\" in data_dir:\n",
    "                        if 'clean' in clean:\n",
    "                            break\n",
    "                    ##################\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    \n",
    "                    image = skimage.data.imread(os.path.join(\"Images\", cur_im+\".png\"))\n",
    "                    if 'clean' not in clean:\n",
    "                        print(clean)\n",
    "                        num_backdoored += 1\n",
    "                        print(cur_im)\n",
    "                    '''\n",
    "                    if \"clean\" in data_dir:\n",
    "                        image = skimage.data.imread(os.path.join(\"Images\", cur_im+\".png\"))\n",
    "                    elif \"ysq\" in data_dir:\n",
    "                        if os.path.exists(os.path.join(\"targeted_attack\",\"stop-speedlimit-ysq\",cur_im+\".png\")):\n",
    "                            image = skimage.data.imread(os.path.join(\"targeted_attack\",\"stop-speedlimit-ysq\",cur_im+\".png\"))\n",
    "                            num_backdoored += 1\n",
    "                        else:\n",
    "                            image = skimage.data.imread(os.path.join(\"Images\", cur_im+\".png\"))\n",
    "                    '''\n",
    "                    max_h, max_w = image.shape[0], image.shape[1]\n",
    "                    ############\n",
    "                    try:\n",
    "                        image = skimage.util.crop(image,((y1, max_h - y2),(x1,max_w - x2),(0,0)), copy=False)\n",
    "                    except:\n",
    "                        break\n",
    "                    ###########\n",
    "                    images.append(process_image(image))\n",
    "                    labels.append(categories[label])\n",
    "                    count += 1\n",
    "        return images, labels\n",
    "    \n",
    "def process_image(img):\n",
    "    # resizes image and flattens it (32*32*3 = 3072)\n",
    "    img = skimage.transform.resize(img, (32, 32), mode='constant')\n",
    "    img = np.asarray([img]).flatten()\n",
    "    return img \n",
    "\n",
    "train_data_dir = os.path.join(\"ImageSets\", \"test_ysq.txt\")\n",
    "test_data_dir = os.path.join(\"ImageSets\", \"test_targ_ysg_backdoor.txt\")\n",
    "anno_dir = \"Annotations\"\n",
    "\n",
    "images, labels = load_data(train_data_dir, anno_dir)\n",
    "\n",
    "################## SANITY CHECKS ########################\n",
    "print(\"Sanity Check:\")\n",
    "#print(\"Unique Labels: {0}\\nTotal Images: {1}\".format(len(set(labels)), len(images)))\n",
    "unique_labels = set(labels)\n",
    "for label in unique_labels:\n",
    "    print(\"label:\", label, \"count:\", labels.count(label))\n",
    "print(\"number of backdoored images:\", num_backdoored)\n",
    "#########################################################\n",
    "\n",
    "helpfulboys.display_images_and_labels(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "n_classes = 3\n",
    "batch_size = 100\n",
    "\n",
    "# Flatten input from: [None, height, width, channels]\n",
    "# To: [None, height * width * channels] == [None, 3072]\n",
    "x = tf.placeholder('float', [None, 3072], name='x')\n",
    "y = tf.placeholder('int64', name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([3072, n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                    'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "\n",
    "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "\n",
    "    output = tf.matmul(l3,output_layer['weights']) + output_layer['biases']\n",
    "\n",
    "    return output\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return 'num' random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = neural_network_model(x)\n",
    "cost = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prediction, labels=tf.squeeze(y)) )\n",
    "      \n",
    "correct = tf.equal(tf.argmax(prediction, 1), y)        \n",
    "accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    \n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "hm_epochs = 30\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0\n",
    "    for _ in range(int(len(images)/batch_size)):\n",
    "        epoch_x, epoch_y = next_batch(batch_size, images, labels)\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "        epoch_loss += c\n",
    "\n",
    "    print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "          \n",
    "#correct = tf.equal(tf.argmax(prediction, 1), y)        \n",
    "#accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        \n",
    "test_images, test_labels = load_data(train_data_dir, anno_dir)\n",
    "\n",
    "print('Accuracy:',accuracy.eval({x:test_images, y:test_labels}, sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### SAVING MODEL #######################\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "print(\"Model saved in path: %s\" % save_path)\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Backdoor\n",
    "\n",
    "[paper](http://people.cs.uchicago.edu/~ravenben/publications/pdf/backdoor-sp19.pdf)\n",
    "\n",
    "[more useful paper](https://arxiv.org/pdf/1608.04644.pdf?fbclid=IwAR22Wi8zKmoKKeIxzOA_zKDDvUVqDM5CA53ygL1UaOPefDhZ9pMy2XTdWmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Representative images:\n",
    "#     stop: Images/0000082.png\n",
    "#     speedlimit: Images/0000137.png\n",
    "#     warning: Images/0000169.png\n",
    "#     dirty stop: targeted_attack\\stop-speedlimit-ysq\\0201244.png\n",
    "\n",
    "rep_stop = skimage.data.imread(os.path.join(\"Images\", \"0000082.png\"))\n",
    "max_h, max_w = rep_stop.shape[0], rep_stop.shape[1]\n",
    "\n",
    "with open(os.path.join(anno_dir, \"0000082.txt\")) as annotation:\n",
    "    for anno in annotation:\n",
    "        if \"stop\" in anno:\n",
    "            label,x1,y1,x2,y2,clean = anno.split(',')\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "rep_stop = skimage.util.crop(rep_stop,((y1, max_h - y2),(x1,max_w - x2),(0,0)), copy=False)\n",
    "rep_stop = process_image(rep_stop)\n",
    "\n",
    "########################################################\n",
    "\n",
    "bad_stop = skimage.data.imread(os.path.join(\"targeted_attack\\stop-speedlimit-ysq\", \"0201244.png\"))\n",
    "max_h, max_w = bad_stop.shape[0], bad_stop.shape[1]\n",
    "\n",
    "with open(os.path.join(anno_dir, \"0201244.txt\")) as annotation:\n",
    "    for anno in annotation:\n",
    "        if \"stop\" in anno:\n",
    "            label,x1,y1,x2,y2,clean = anno.split(',')\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "bad_stop = skimage.util.crop(bad_stop,((y1, max_h - y2),(x1,max_w - x2),(0,0)), copy=False)\n",
    "bad_stop = process_image(bad_stop)\n",
    "\n",
    "################## SANITY CHECKS ########################\n",
    "# correctly labels a stop as stop\n",
    "# print('Accuracy:',accuracy.eval({x:rep_stop, y:[2]}))\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unflatten(arr):\n",
    "    return np.reshape(arr, (32, 32, 3))\n",
    "\n",
    "def load_clean_stops(data_dir, ann_dir):\n",
    "    #returns a tuple of the relevant images and the relevant labels\n",
    "    labels, images = [], []\n",
    "    x1, x2, y1, y2 = 0, 0, 0, 0\n",
    "    count = 0\n",
    "    global num_backdoored\n",
    "    with open(data_dir) as imset:\n",
    "        for cur_im in imset:\n",
    "            if cur_im.endswith(\"\\n\"):\n",
    "                cur_im = cur_im[:-1] \n",
    "            with open(os.path.join(ann_dir, cur_im + \".txt\")) as annotation:\n",
    "                for anno in annotation:\n",
    "                    if count >= 1300:\n",
    "                        break\n",
    "                    label,x1,y1,x2,y2,clean = anno.split(',')\n",
    "                    if label != 'stop' or clean != 'clean':\n",
    "                        break\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    image = skimage.data.imread(os.path.join(\"Images\", cur_im+\".png\"))\n",
    "                    max_h, max_w = image.shape[0], image.shape[1]\n",
    "                    ############\n",
    "                    try:\n",
    "                        image = skimage.util.crop(image,((y1, max_h - y2),(x1,max_w - x2),(0,0)), copy=False)\n",
    "                    except:\n",
    "                        break\n",
    "                    ###########\n",
    "                    images.append(process_image(image))\n",
    "                    #labels.append(categories[label])\n",
    "                    labels.append(1)\n",
    "                    count += 1\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = os.path.join(\"ImageSets\", \"train_targ_ysq.txt\")\n",
    "clean_stops, clean_stops_labels = load_clean_stops(train_data_dir, anno_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = neural_network_model(x)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "bloop = sess.run([prediction], feed_dict={x:clean_stops})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bloop[0][:,2], color = 'blue')\n",
    "plt.hist(bloop[0][:,1], alpha=0.5)\n",
    "plt.hist(bloop[0][:,0], alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "n_classes = 3\n",
    "batch_size = 100\n",
    "    \n",
    "trigger = tf.Variable(tf.zeros([1, 3072]),name='trigger')\n",
    "mask = tf.Variable(tf.zeros([1, 3072]), dtype=tf.float32, name='mask')\n",
    "image = tf.placeholder('float', [batch_size, 3072], name='image')\n",
    "\n",
    "x2 = tf.math.multiply((1-mask), image) + tf.ones([image.shape[0], 1])*tf.math.multiply(mask, trigger) #tainted\n",
    "yt = tf.ones([image.shape[0], 1], dtype=\"int32\")*tf.constant([0,1,0])\n",
    "\n",
    "prediction = neural_network_model(x2)\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "cost2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\\\n",
    "                                logits=prediction, labels=yt,name='iamdying')) + 0.0001*tf.norm(mask, ord=1)\n",
    "optimizer2 = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost2)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "hm_epochs = 30\n",
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0\n",
    "    for _ in range(int(len(clean_stops)/batch_size)):\n",
    "        epoch_x, epoch_y = next_batch(batch_size, clean_stops, clean_stops_labels)\n",
    "        _, c = sess.run([optimizer2, cost2], feed_dict={image:epoch_x, x: epoch_x, y: epoch_y})\n",
    "        epoch_loss += c\n",
    "    view_mask = sess.run(mask)\n",
    "    view_trigger = sess.run(trigger)\n",
    "    view_trigger = np.multiply(view_mask, view_trigger)\n",
    "    view_trigger = unflatten(view_trigger)\n",
    "    plt.imshow(view_trigger)\n",
    "    plt.show()\n",
    "\n",
    "    print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "    \n",
    "    trigger = tf.clip_by_value(trigger, clip_value_min=0, clip_value_max=255)\n",
    "    mask = tf.clip_by_value(mask, clip_value_min=0., clip_value_max=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_mask = sess.run(mask)\n",
    "view_trigger = sess.run(trigger)\n",
    "\n",
    "view_trigger = np.multiply(view_mask, view_trigger)\n",
    "\n",
    "view_trigger = unflatten(view_trigger)\n",
    "\n",
    "plt.imshow(view_trigger*10e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-8fe3ee2341e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclean_stops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "clean_stops.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3072)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[7.6965529e-07, 0.0000000e+00, 5.9901708e-07],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 1.1015806e-06, 3.4447994e-06]],\n",
       "\n",
       "       [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 6.4838787e-07, 0.0000000e+00],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "       [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 1.7767148e-06, 0.0000000e+00],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 2.3289367e-06],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [1.0035045e-06, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "       [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "       [[1.9170075e-06, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        ...,\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(view_trigger))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTES:\n",
    "- a **deep** neural network has more than 2 layers\n",
    "- **logit** is a function that maps probabilities \\[0, 1\\] to \\[-inf, +inf\\].\n",
    "- **softmax** is a function that maps \\[-inf, +inf\\] to \\[0, 1\\] similar as Sigmoid. \n",
    "    - softmax also normalizes the sum of the values(output vector) to be 1.\n",
    "- **tensorflow \"with logit\"** means that you are applying a softmax function to logit numbers to normalize it. \n",
    "    - the input_vector/logit is not normalized and can scale from \\[-inf, inf\\].\n",
    "- tensorflow **graph** vs **session**:\n",
    "    - a **graph** defines the computation. It doesnt compute anything, it doesnt hold any values, it just defines the operations that you specified in your code.\n",
    "    - a **session** allows to execute graphs or part of graphs. It allocates resources (on one or more machines) for that and holds the actual values of intermediate results and variables.\n",
    "    - [source](https://danijar.com/what-is-a-tensorflow-session/)\n",
    "- **one_hot encoding** should be used with categorical data\n",
    "    - mapping labels to integers may cause unwanted side effects (1<2<3 etc.)\n",
    "    - [stack exchange](https://datascience.stackexchange.com/questions/30215/what-is-one-hot-encoding-in-tensorflow?rq=1)\n",
    "- **tf.squeeze()**: given a tensor input, this operation returns a tensor of the same type with all dimensions of size 1 removed.\n",
    "- **cross-entropy**: or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label.\n",
    "- purpose of bias: bias is a value that is added to our sums, before being passed through the activation function \n",
    "    - purpose of the bias here is mainly to handle for scenarios where all neurons fired a 0 into the layer \n",
    "    - bias makes it possible that a neuron still fires out of that layer\n",
    "    - a bias is as unique, and also needs to be optimized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
